{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cca7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas y clase DateFeatureExtractor definida.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variable):\n",
    "        self.variable = variable\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for var in self.variable:\n",
    "            # Aseguramos formato datetime\n",
    "            X[var] = pd.to_datetime(X[var])\n",
    "            \n",
    "            # Extraemos características\n",
    "            X[var + '_year'] = X[var].dt.year\n",
    "            X[var + '_month'] = X[var].dt.month\n",
    "            X[var + '_day'] = X[var].dt.day\n",
    "            X[var + '_weekday'] = X[var].dt.dayofweek\n",
    "            \n",
    "            # Eliminamos la columna original para evitar errores en el modelo\n",
    "            X.drop(columns=[var], inplace=True)\n",
    "        return X\n",
    "\n",
    "print(\"Librerías importadas y clase DateFeatureExtractor definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cf7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline cargado exitosamente desde: ../models/sales_forecasting_pipeline_v1.pkl\n",
      "Datos cargados: 651372 registros totales.\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar el Pipeline Entrenado\n",
    "path_pipeline = '../models/sales_forecasting_pipeline_v1.pkl'\n",
    "\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(path_pipeline)\n",
    "    print(f\"✅ Pipeline cargado exitosamente desde: {path_pipeline}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al cargar el pipeline: {e}\")\n",
    "\n",
    "# 2. Cargar los Datos Originales\n",
    "df = pd.read_excel('../data/raw/data_sales_forecasting.xlsx', sheet_name='Base de Datos')\n",
    "\n",
    "# Ordenar por fecha \n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "df.sort_values('Fecha', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Datos cargados: {df.shape[0]} registros totales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e132cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generación de Dataset de Inferencia ---\n",
      "Registros para predecir: 130275\n",
      "Rango de fechas a predecir: 2024-04-28 00:00:00 hasta 2024-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "split_point = int(len(df) * 0.80)\n",
    "\n",
    "# Creamos el dataset de test (últimos 20%)\n",
    "df_test = df.iloc[split_point:].copy()\n",
    "\n",
    "# Separamos las características (X) del objetivo real (y)\n",
    "X_test = df_test.drop(columns=['Venta_Neta_GTQ'])\n",
    "\n",
    "y_real = df_test['Venta_Neta_GTQ']\n",
    "\n",
    "print(\"--- Generación de Dataset de Inferencia ---\")\n",
    "print(f\"Registros para predecir: {len(X_test)}\")\n",
    "print(f\"Rango de fechas a predecir: {X_test['Fecha'].min()} hasta {X_test['Fecha'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55259ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando predicciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\envs\\env_papd_project\\lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Predicciones generadas con éxito!\n"
     ]
    }
   ],
   "source": [
    "print(\"Generando predicciones...\")\n",
    "\n",
    "predicciones = loaded_pipeline.predict(X_test)\n",
    "\n",
    "print(\"¡Predicciones generadas con éxito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb1853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Fecha  No_Tienda  \\\n",
      "521097 2024-04-28      14012   \n",
      "521098 2024-04-28      14010   \n",
      "521099 2024-04-28      14002   \n",
      "521100 2024-04-28      14000   \n",
      "521101 2024-04-28      14002   \n",
      "\n",
      "                                        Descripcion_Cupon  Venta_Real  \\\n",
      "521097  Mediana de especialidad + orilla de queso por Q75       59.53   \n",
      "521098  Grande de Queso, 1 ING o Esp + Mediana de Ques...       68.79   \n",
      "521099                 Pizzas Grandes Esp Q80 C/U 2 o Mas      142.86   \n",
      "521100                        Mediana de Especialidad Q50       44.64   \n",
      "521101                                         2 o Mas CC       71.43   \n",
      "\n",
      "        Venta_Predicha  Error_Absoluto  \n",
      "521097       59.530000    1.705303e-13  \n",
      "521098       69.604389    8.143889e-01  \n",
      "521099      142.860000    3.694822e-13  \n",
      "521100       44.759100    1.191000e-01  \n",
      "521101       71.876000    4.460000e-01  \n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con los resultados\n",
    "resultados_df = X_test.copy() \n",
    "\n",
    "# Agregamos la predicción\n",
    "resultados_df['Venta_Predicha'] = predicciones\n",
    "\n",
    "# Agregamos la venta real para referencia \n",
    "resultados_df['Venta_Real'] = y_real\n",
    "\n",
    "# Calculamos el error absoluto para cada fila \n",
    "resultados_df['Error_Absoluto'] = abs(resultados_df['Venta_Real'] - resultados_df['Venta_Predicha'])\n",
    "\n",
    "# Seleccionamos columnas clave para el reporte final\n",
    "columnas_reporte = [\n",
    "    'Fecha', \n",
    "    'No_Tienda', \n",
    "    'Descripcion_Cupon', \n",
    "    'Venta_Real', \n",
    "    'Venta_Predicha', \n",
    "    'Error_Absoluto'\n",
    "]\n",
    "\n",
    "df_export = resultados_df[columnas_reporte]\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(df_export.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e4d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo de predicciones generado exitosamente en: ../data/processed/predicciones_test_set.csv\n"
     ]
    }
   ],
   "source": [
    "# Definir ruta de salida\n",
    "output_csv_path = '../data/processed/predicciones_test_set.csv'\n",
    "\n",
    "# Asegurarse que la carpeta exista\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "df_export.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Archivo de predicciones generado exitosamente en: {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_papd_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
